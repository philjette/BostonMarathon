trimmed_data<-event_summary %>% filter(count_events>10)
trimmed_data<-trimmed_data %>% mutate(health_impact = total_fatalities+total_injuries)
trimmed_data<-trimmed_data[order(trimmed_data$health_impact, decreasing=TRUE),]
trimmed_data_plot<-head(trimmed_data,10)
ggplot(data=trimmed_data_plot, aes(x=reorder(EVTYPE, -health_impact), y=health_impact)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=health_impact), vjust=-0.3, size=3.5)+
theme_minimal()+
ggtitle("Health Impact of Major Weather Events")+
xlab("Event Type") + ylab("Fatalities and Injuries")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
trimmed_data<-trimmed_data[order(trimmed_data$total_propdmg, decreasing=TRUE),]
trimmed_data_plot<-head(trimmed_data,10)
ggplot(data=trimmed_data_plot, aes(x=reorder(EVTYPE, -total_propdmg), y=total_propdmg)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=total_propdmg), vjust=-0.3, size=3.5)+
theme_minimal()+
ggtitle("Economic Impact of Major Weather Events")+
xlab("Event Type") + ylab("Property and Crop Damage")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
require(datasets)
data(swiss)
?swiss
summary(lm(Fertility ~ . data=swiss))$coeffcients
summary(lm(Fertility ~ ., data=swiss))$coeffcients
lm(Fertility ~ ., data=swiss
)
summary(lm(Fertility ~ ., data=swiss))$coeffcients
data(mtcars)
data<-mtcars
colnames(mtcars)
class(mtcars$cyl)
data$cyl<-factor(data$cyl)
class(data$cyl)
lm(mpg~cyl+cyl)
fit<-lm(mpg~cyl+cyl, data = data)
summary(fit)
levels(data$cyl)
11.5636-6.9208
summary(fit)$coef[3, 1]
fit <- lm(mpg ~ cyl + wt, mtcars)
summary(fit)$coef[3, 1]
mtcars$cyl <- factor(mtcars$cyl)
mtcars$am <- factor(mtcars$am)
levels(mtcars$am) <- c('-auto', '-manual')
fit <- lm(mpg ~ cyl + wt, mtcars)
summary(fit)$coef[3, 1]
mtcars$cyl <- factor(mtcars$cyl)
fit <- lm(mpg ~ cyl + wt, mtcars)
summary(fit)$coef[3, 1]
summary(fit)
fit2 <- lm(mpg ~ cyl, mtcars)
summary(fit2)
fit_non_interaction <- lm(mpg ~ cyl + wt, mtcars)
summary(fit_non_interaction)$adj.r.squared
fit_interaction <- lm(mpg ~ cyl + wt + cyl:wt, mtcars)
summary(fit_interaction)$adj.r.squared
suppressMessages(library(lmtest))
install.packages("lmtest")
suppressMessages(library(lmtest))
lrtest(fit_interaction, fit_non_interaction)
head(data,2)
?bunzip2
data<-data("mtcars")
colnames(data)
data<-data("mtcars")
data<-mtcars
colnames(data)
summary(data)
class(colnames(data))
class(data)
class(data[,1])
class(data[1,])
class(data[,1:3])
colnames(data)
library(ggplot2)
library(dplyr)
data<-mtcars
colnames(data)
head(data,2)
?mtcars
data$vs<-factor(data$vs)
data$am<-factor(data$am)
summary(mtcars$mpg)
ggplot(data, aes(x = am, y = mpg)) +
geom_boxplot()
ggplot(data, aes(x = am, y = mpg)) + geom_boxplot(fill=blue)
+ scale_x_discrete(name = "Transmission Type") + scale_y_continuous(name = "MPG")
ggplot(data, aes(x = am, y = mpg)) + geom_boxplot(fill=blue) + scale_x_discrete(name = "Transmission Type") + scale_y_continuous(name = "MPG")
ggplot(data, aes(x = am, y = mpg)) + geom_boxplot(fill="blue") + scale_x_discrete(name = "Transmission Type") + scale_y_continuous(name = "MPG")
ggplot(data, aes(x = am, y = mpg)) + geom_boxplot(fill="#4271AE") + scale_x_discrete(name = "Transmission Type") + scale_y_continuous(name = "MPG")
data$vs<-replace(data$vs,data$vs==0,"V")
data$vs<-replace(data$vs,data$vs=="0","V")
fit <- lm(mpg ~ am, data = data)
summary(fit)
colnames(data)
fit <- lm(mpg ~ am + wt + cyl, data = data)
summary(fit)
fit <- lm(mpg ~ am, data = data)
fit2 <- lm(mpg ~ am + wt + cyl, data = data)
anova(fit, bestfit)
anova(fit, fit2)
plot(bestfit)
plot(fit2)
plot(data$mpg, fit2.res,
+     ylab="Residuals", xlab="Waiting Time",
+     main="Old Faithful Eruptions")
fit2.res<-residuals(fit2)
plot(data$mpg, fit2.res, ylab="Residuals", xlab="Waiting Time", main="Old Faithful Eruptions")
plot(data$mpg, fit2.res, ylab="Residuals", xlab="MPG", main="MPG Model Residuals")
mar.orig <- par()$mar  # save the original values
par(mar = c(2, 2, 2, 2))  # set your new values
plot(fit2, which = c(1:1))
fit2.res<-residuals(fit2)
shapiro.test(fit2.res)
fit2.res<-residuals(fit2)
shapiro.test(fit2.res)
mar.orig <- par()$mar  # save the original values
par(mar = c(2, 2, 2, 2))  # set your new values
plot(fit2, which = c(1:1))
library(gridExtra)
install.packages("gridExtra")
library(gridExtra)
cyl_dist <- qplot(data$cyl)
mpg_dist <- qplot(data$mpg)
wt_dist <- qplot(data$wt)
am_dist <- qplot(data$am)
grid.arrange(mpg_dist, wt_dist, qsec_dist, am_dist, ncol = 2)
ggplot(data, aes(am)) + geom_bar()
library(ggplot2)
ggplot(data, aes(am)) + geom_bar()
ggplot(data, aes(class)) + geom_bar()
ggplot(data, aes(x = cyl, y = mpg)) + geom_boxplot(fill="#4271AE") + scale_x_discrete(name = "Cylinders") + scale_y_continuous(name = "MPG")
ggplot(data, aes(x = as.factor(cyl), y = mpg)) + geom_boxplot(fill="#4271AE") + scale_x_discrete(name = "Cylinders") + scale_y_continuous(name = "MPG")
summary(fit)
summary(fit2)
ggplot(data, aes(x = am, y = mpg)) + geom_boxplot(fill="#4271AE") + scale_x_discrete(name = "Transmission Type") + scale_y_continuous(name = "MPG")
install.packages("twitteR")
install.packages("ROAuth")
install.packages("httr")
library(twitteR)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
setup_twitter_oauth(api_key,api_secret)
setup_twitter_oauth(api_key,api_secret)
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
searchTwitter('TELUS')
tweets_TELUS <- searchTwitter('TELUS', n=1500)
class(tweets_TELUS)
feed_TELUS = laply(tweets_TELUS, function(t) t$getText())
library(dplyr)
feed_TELUS = laply(tweets_TELUS, function(t) t$getText())
feed_TELUS = lapply(tweets_TELUS, function(t) t$getText())
View(feed_TELUS)
class(feed_TELUS)
test<-data.frame(feed_TELUS)
View(test)
feed_TELUS = sapply(tweets_TELUS, function(t) t$getText())
head(feed_TELUS)
test<-data.frame(feed_TELUS)
View(test)
tweets_TELUS <- searchTwitter('TELUS')
tweets_TELUS <- searchTwitter('TELUS')
View(tweets_TELUS)
tweets_TELUS <- searchTwitter('TELUS', n=10000)
feed_TELUS = sapply(tweets_TELUS, function(t) t$getText())
feed_TELUS <- data.frame(feed_TELUS)
View(feed_TELUS)
setwd("~/")
write.csv(feed_TELUS, "TELUS_Tweets.csv")
install.packages("devtools")
library(devtools)
tweetsDF <- twListToDF(tweets_TELUS)
View(tweetsDF)
write.csv(tweetsDF, "TELUS_Tweets.csv")
write.csv(tweetsDF, "TELUS_Tweets.csv")
install.packages("rtweet")
library(twitteR)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
library(plyr)
heaD(tweetsDF)
head(tweetsDF)
library(stringr)
library(ggplot2)
source('~/.active-rstudio-document')
pos <- scan('C:\Users\T891015\Documents\Phil\Sentiment Analysis\positive-words.txt', what='character', comment.char=';') #folder with positive dictionary
neg <- scan('C:\Users\T891015\Documents\Phil\Sentiment Analysis\negative-words.txt', what='character', comment.char=';') #folder with negative dictionary
pos <- scan("C:\Users\T891015\Documents\Phil\Sentiment Analysis\positive-words.txt", what='character', comment.char=';') #folder with positive dictionary
neg <- scan("C:\Users\T891015\Documents\Phil\Sentiment Analysis\negative-words.txt", what='character', comment.char=';')
pos <- scan("C:\\Users\T891015\Documents\Phil\Sentiment Analysis\positive-words.txt", what='character', comment.char=';') #folder with positive dictionary
neg <- scan("C:\\Users\T891015\Documents\Phil\Sentiment Analysis\negative-words.txt", what='character', comment.char=';') #folder with negative dictionary
pos <- scan("C:\\Users\\T891015\Documents\Phil\Sentiment Analysis\positive-words.txt", what='character', comment.char=';') #folder with positive dictionary
neg <- scan("C:\\Users\\T891015\Documents\Phil\Sentiment Analysis\negative-words.txt", what='character', comment.char=';') #folder with negative dictionary
pos <- scan("C:\\Users\\T891015\\Documents\\Phil\\Sentiment Analysis\\positive-words.txt", what='character', comment.char=';') #folder with positive dictionary
neg <- scan("C:\\Users\\T891015\\Documents\\Phil\\Sentiment Analysis\\negative-words.txt", what='character', comment.char=';')
tweetsDF$text<-as.factor(tweetsDF$text)
scores <- score.sentiment(tweetsDF$text, pos.words, neg.words, .progress='text')
scores <- score.sentiment(tweetsDF$text, pos, neg, .progress='text')
tweetsDF$text<-as.factor(tweetsDF$text)
tweetsDF$text <- sapply(tweetsDF$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
scores <- score.sentiment(tweetsDF$text, pos, neg, .progress='text')
#total score calculation: positive / negative / neutral
stat <- scores
stat$created <- tweetsDF$created
stat$created <- as.Date(stat$created)
stat <- mutate(stat, tweet=ifelse(stat$score > 0, 'positive', ifelse(stat$score < 0, 'negative', 'neutral')))
by.tweet <- group_by(stat, tweet, created)
by.tweet <- summarise(by.tweet, number=n())
stat <- scores
stat$created <- tweetsDF$created
stat$created <- as.Date(stat$created)
stat <- mutate(stat, tweet=ifelse(stat$score > 0, 'positive', ifelse(stat$score < 0, 'negative', 'neutral')))
by.tweet <- group_by(stat, tweet, created)
by.tweet <- summarise(by.tweet, number=n())
library(rtweet)
source('~/Phil/Sentiment Analysis/TELUS_Sentiment.R')
source('~/Phil/Sentiment Analysis/TELUS_Sentiment.R')
source('~/Phil/Sentiment Analysis/TELUS_Sentiment.R')
source('~/Phil/Sentiment Analysis/TELUS_Sentiment.R')
tweets_TELUS <- search_tweets('TELUS', n=10000)
vignette("auth", package = "rtweet")
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
library(ROAuth)
appname <- "twitter_scrape_telus"
twitter_token <- create_token(
app = appname,
consumer_key = api_key,
consumer_secret = api_secret)
twitter_token <- create_token(
app = appname,
consumer_key = api_key,
consumer_secret = api_secret)
install.packages("httpuv")
library(httpuv)
twitter_token <- create_token(
app = appname,
consumer_key = api_key,
consumer_secret = api_secret)
tweets_TELUS <- search_tweets('TELUS', n=10000, include_rts = FALSE)
tweetsDF <- twListToDF(tweets_TELUS)
class(tweets_TELUS)
library (devtools)
tweetsDF <- twListToDF(tweets_TELUS)
library(twitteR)
tweetsDF <- twListToDF(tweets_TELUS)
library(data.table)
install.packages("data.table")
library(data.table)
tweetsDF<-rbindlist(tweets_TELUS)
View(tweets_TELUS)
tweets_TELUS[1]
tweets_TELUS[[1]]
twt_df <- do.call("rbind", tweets_TELUS)
View(twt_df)
twt_df <- data.frame(do.call("rbind", tweets_TELUS))
View(twt_df)
install.packages("caret")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModelling")
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
inTrain<-createDataPartition(y=iris$Species, p=0.7, list=False)
library(caret)
version
inTrain<-createDataPartition(y=iris$Species, p=0.7, list=False)
inTrain<-createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain]
testing<-iris[-inTrain,]
ggplot(Petal.Width, Sepal.Width,colour=Species,data=training)
qplot(Petal.Width, Sepal.Width,colour=Species,data=training)
modFit<-train(Species ~ .,method="rpart",data=training)
print(modFit$finalModel)
install.packages("rattle")
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
install.packages("rattle")
install.packages("RGTK2")
install.packages("RGtK2")
install.packages("RGtk2")
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
View(TrainSet)
colSums(!is.na(inTrain)
)
test<-inTrain[, colSums(is.na(inTrain))/colSums(!is.na(inTrain)) <.95]
test
test<-inTrain[, colSums(is.na(df)) < nrow(df) * 0.5]
test<-inTrain[, colSums(is.na(inTrain)) < nrow(inTrain) * 0.5]
test
test<-training[, colSums(is.na(training)) < nrow(training) * 0.5]
test
training<-training[, colSums(is.na(training)) < nrow(training) * 0.5]
length(names(training))
length(names(testing))
testing<-testing[,!(names(testing) %in% names(training))]
dim(testing)
length(names(testing))
length(names(training))
training<-training[,!(names(training) %in% names(testing))]
dim(training)
testing  <- read.csv(url(UrlTest))
dim(testing)
test<-testing[,(names(testing) %in% names(training))]
dim(test)
testing<-testing[,(names(testing) %in% names(training))]
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
test<-sapply(TrainSet, function(x) mean(is.na(x)))
summarise(training, is.na())
summarise(training, num_na = is.na())
summarise(training, num_na = is.na(x))
library(dplyr)
summarise(training, num_na = is.na(x))
summarise(training, num_na = is.na())
test
training <- training[, -(1:5)]
dim(training)
testing<-testing[,(names(testing) %in% names(training))]
dim(training)
dim(testing)
training <- read.csv(url(UrlTrain))
testing  <- read.csv(url(UrlTest))
training<-training[, colSums(is.na(training)) < nrow(training) * 0.5]
training <- training[, -(1:5)]
dim(training)
View(training)
View(testing)
testing<-testing[,(names(testing) %in% names(training))]
dim(training)
dim(testing)
View(training)
View(testing)
training <- read.csv(url(UrlTrain))
testing  <- read.csv(url(UrlTest))
dim(training)
dim(testing)
training<-training[, colSums(is.na(training)) < nrow(training) * 0.5]
testing<-testing[,(names(testing) %in% names(training))]
dim(training)
dim(testing)
View(training)
View(testing)
training <- read.csv(url(UrlTrain))
testing  <- read.csv(url(UrlTest))
View(testing)
View(training)
head(training$classe)
head(testing$classe)
training<-training[, colSums(is.na(training)) < nrow(training) * 0.5]
training <- training[, -(1:5)]
testing<-testing[,(names(testing) %in% C(names(training),"problem_id")]
testing<-testing[,(names(testing) %in% c(names(training),"problem_id")]
testing<-testing[,(names(testing) %in% c(names(training),"problem_id"))]
dim(training)
dim(testing)
set.seed(111)
RandForestModel <- randomForest(classe ~ ., data = training, ntree = 1000)
install.packages("randomForest")
library(randomForest)
RandForestModel <- randomForest(classe ~ ., data = training, ntree = 1000)
RandForestModel <- randomForest(classe ~ ., data = partTrain, ntree = 1000)
inTrain  <- createDataPartition(training$classe, p=0.7, list=FALSE)
partTrain <- training[inTrain, ]
partTest  <- training[-inTrain, ]
RandForestModel <- randomForest(classe ~ ., data = partTrain, ntree = 1000)
summary(partTrain)
source('~/.active-rstudio-document')
class(names(partTrain))
class(partTrain)
class(partTrain[,])
View(partTrain)
View(partTrain)
randFOrestControl <- trainControl(method="cv", number=3, verboseIter=FALSE)
randForestModel <- train(classe ~ ., data=TrainSet, method="rf",
trControl=controlRF)
set.seed(111)
RandForestModel <- randomForest(classe ~ ., data = partTrain, ntree = 1000)
st(partTrain)
str(partTrain)
training <- read.csv(url(UrlTrain),na.strings=c("NA","#DIV/0!",""),stringsAsFactors = F)
testing  <- read.csv(url(UrlTest),na.strings=c("NA","#DIV/0!",""),stringsAsFactors = F)
training<-training[, colSums(is.na(training)) < nrow(training) * 0.5]
training <- training[, -(1:8)]
testing<-testing[,(names(testing) %in% c(names(training),"problem_id"))]
dim(training)
dim(testing)
inTrain  <- createDataPartition(training$classe, p=0.7, list=FALSE)
partTrain <- training[inTrain, ]
partTest  <- training[-inTrain, ]
set.seed(111)
RandForestModel <- randomForest(classe ~ ., data = partTrain, ntree = 1000)
modFit<-train(Classe~ .,data=partTrain, method="rf", prox=TRUE)
View(partTrain)
modFit<-train(partTrain$Classe~ .,data=partTrain, method="rf", prox=TRUE)
modFit<-train(Classe~ .,data=partTrain, method="rf", prox=TRUE)
setting <- trainControl(method="cv", 5)
RandomForest <- train(classe ~ ., data=partTrain, method="rf", trControl=setting, ntree=250)
RandomForest
set.seed(111)
control <- trainControl(method="cv", 5)
modFit <- train(classe ~ ., data=partTrain, method="rf", trControl=control, ntree=250)
predict_model <- predict(modFit, partTest)
confusionMatrix(partTest$classe, predict_model)
predict_model <- predict(modFit, testing)
predict_model
install.packages("Rtools")
?lm
?predict
?colSums
?dgamma
?show
?mean
?getMethod
?showMethods
?getMethod
?getClass
?getS3method
?showMethods
install.packages("plotly")
library(plotly)
plot_ly(mtcars, x=wt, y=mpg, mode="markers")
mtcars
plot_ly(mtcars, x=wt, y=mpg, mode="markers")
plot_ly(mtcars, x = wt, y = mpg, mode="markers")
plot_ly(mtcars, x = mtcars$wt, y = mtcars$mpg, mode="markers")
?Sys.Date
Sys.Date
Sys.Date()
setwd("~/BostonMarathon")
source('~/BostonMarathon/BostonMarathonAnalysis.R')
#we have a bunch of splits that need to be converted to seconds
#create new fields for these values
results$Official.Times<-period_to_seconds(hms(results$Official.Time))
results$Official.Times<-period_to_seconds(hms(results$Official.Time))/60
View(results)
?as.double
?round
#convert official time to minutes
results$Official.Times<-round(period_to_seconds(hms(results$Official.Time))/60)
View(results)
countries<-unique(results$Country)
sort(countries)
countries<-sort(countries)
library(ggplot2)
shiny::runApp()
runApp()
View(results)
View(results)
runApp()
runApp()
class(results$Official.Times)
runApp()
x    <- subset(results, Country=input$country, select=c(Official.Times))
class(x)
View(x)
runApp()
runApp()
runApp()
sd(results$Official.Time)
sd(results$Official.Times)
results$Official.Times<-round(period_to_seconds(hms(results$Official.Times))/60)
source('~/BostonMarathon/BostonMarathonAnalysis.R')
source('~/BostonMarathon/BostonMarathonAnalysis.R')
sd(results$Official.Times)
runApp()
View(results)
runApp()
dim(results)
dim(results)[1]
runApp()
runApp()
runApp()
?hist
runApp()
runApp()
library(dplr)
library(dplyr)
test<-aggregate(Country~year, results, count())
test<-aggregate(Country~year, results, count
)
drop<-c("VIE","EGY","GRN","ZIM","BAH","FLK","UGA","VGB","ALG","NCA","TCA","NGR","PAR","KUW","MLT","MGL","KSA",
"BDI","ALB","QAT","CYP","PAK","SMR","OMA","BLR","LIE","AHO","BUL","BRN","JOR")
'%!in%' <- function(x,y)!('%in%'(x,y))
results<-subset(results, Country %!in% drop)
runApp()
results<-rbind(mar2015, mar2016, mar2017)
results<-subset(results, Country %!in% drop)
source('~/BostonMarathon/BostonMarathonAnalysis.R')
runApp()
class(results$Official.Times,)
class(results$Official.Times)
runApp()
runApp()
runApp()
runApp()
write.csv(results,"compiled_data.csv")
source('~/BostonMarathon/BostonMarathonAnalysis.R')
runApp()
runApp()
runApp()
runApp()
